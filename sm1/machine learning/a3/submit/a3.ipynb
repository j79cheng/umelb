{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "korean-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "\n",
    "train_data_count = open(\"train_count.csv\",'r').readlines()\n",
    "train_data_tfidf = open(\"train_tfidf.csv\",'r').readlines()\n",
    "dev_data_count = open(\"dev_count.csv\",'r').readlines()\n",
    "dev_data_tfidf = open(\"dev_tfidf.csv\",'r').readlines()\n",
    "test_data_count = open(\"test_count.csv\",'r').readlines()\n",
    "test_data_tfidf = open(\"test_tfidf.csv\",'r').readlines()\n",
    "\n",
    "\n",
    "train_name = []\n",
    "train_count = []\n",
    "train_tfidf = []\n",
    "y_train = []\n",
    "\n",
    "dev_name = []\n",
    "dev_count = []\n",
    "dev_tfidf = []\n",
    "y_dev = []\n",
    "\n",
    "test_name = []\n",
    "test_count = []\n",
    "test_tfidf = []\n",
    "y_test = []\n",
    "\n",
    "#transfer count data\n",
    "\n",
    "for i in range(1,len(train_data_count)):\n",
    "    train_data_count[i] = train_data_count[i].strip().split(\",\")\n",
    "    y_train.append(train_data_count[i][0])\n",
    "    train_name.append(train_data_count[i][1])\n",
    "    for j in range(2, len(train_data_count[i])):\n",
    "        train_data_count[i][j] = train_data_count[i][j].strip('\"').strip().strip(\"[]()\")\n",
    "    count_info = []\n",
    "    for j in range(1, int(len(train_data_count[i])/2)):\n",
    "        unit_info = []\n",
    "        unit_info.append(train_data_count[i][2*j])\n",
    "        unit_info.append(train_data_count[i][2*j+1])\n",
    "        count_info.append(unit_info)\n",
    "    train_count.append(count_info)    \n",
    "    \n",
    "for i in range(1,len(dev_data_count)):\n",
    "    dev_data_count[i] = dev_data_count[i].strip().split(\",\")\n",
    "    y_dev.append(dev_data_count[i][0])\n",
    "    dev_name.append(dev_data_count[i][1])\n",
    "    for j in range(2, len(dev_data_count[i])):\n",
    "        dev_data_count[i][j] = dev_data_count[i][j].strip('\"').strip().strip(\"[]()\")\n",
    "    count_info = []\n",
    "    for j in range(1, int(len(dev_data_count[i])/2)):\n",
    "        unit_info = []\n",
    "        unit_info.append(dev_data_count[i][2*j])\n",
    "        unit_info.append(dev_data_count[i][2*j+1])\n",
    "        count_info.append(unit_info)\n",
    "    dev_count.append(count_info)    \n",
    "    \n",
    "for i in range(1,len(test_data_count)):\n",
    "    test_data_count[i] = test_data_count[i].strip().split(\",\")\n",
    "    y_test.append(test_data_count[i][0])\n",
    "    test_name.append(test_data_count[i][1])\n",
    "    for j in range(2, len(test_data_count[i])):\n",
    "        test_data_count[i][j] = test_data_count[i][j].strip('\"').strip().strip(\"[]()\")\n",
    "    count_info = []\n",
    "    for j in range(1, int(len(test_data_count[i])/2)):\n",
    "        unit_info = []\n",
    "        unit_info.append(test_data_count[i][2*j])\n",
    "        unit_info.append(test_data_count[i][2*j+1])\n",
    "        count_info.append(unit_info)\n",
    "    test_count.append(count_info)    \n",
    "    \n",
    "#transfer tfidf data\n",
    "    \n",
    "for i in range(1,len(train_data_tfidf)):\n",
    "    train_data_tfidf[i] = train_data_tfidf[i].strip().split(\",\")\n",
    "    for j in range(2, len(train_data_tfidf[i])):\n",
    "        train_data_tfidf[i][j] = train_data_tfidf[i][j].strip('\"').strip().strip(\"[]()\")\n",
    "    tfidf_info = []\n",
    "    for j in range(1, int(len(train_data_tfidf[i])/2)):\n",
    "        unit_info = []\n",
    "        unit_info.append(train_data_tfidf[i][2*j])\n",
    "        unit_info.append(train_data_tfidf[i][2*j+1])\n",
    "        tfidf_info.append(unit_info)\n",
    "    train_tfidf.append(tfidf_info)\n",
    "    \n",
    "for i in range(1,len(dev_data_tfidf)):\n",
    "    dev_data_tfidf[i] = dev_data_tfidf[i].strip().split(\",\")\n",
    "    for j in range(2, len(dev_data_tfidf[i])):\n",
    "        dev_data_tfidf[i][j] = dev_data_tfidf[i][j].strip('\"').strip().strip(\"[]()\")\n",
    "    tfidf_info = []\n",
    "    for j in range(1, int(len(dev_data_tfidf[i])/2)):\n",
    "        unit_info = []\n",
    "        unit_info.append(dev_data_tfidf[i][2*j])\n",
    "        unit_info.append(dev_data_tfidf[i][2*j+1])\n",
    "        tfidf_info.append(unit_info)\n",
    "    dev_tfidf.append(tfidf_info)\n",
    "    \n",
    "for i in range(1,len(test_data_tfidf)):\n",
    "    test_data_tfidf[i] = test_data_tfidf[i].strip().split(\",\")\n",
    "    for j in range(2, len(test_data_tfidf[i])):\n",
    "        test_data_tfidf[i][j] = test_data_tfidf[i][j].strip('\"').strip().strip(\"[]()\")\n",
    "    tfidf_info = []\n",
    "    for j in range(1, int(len(test_data_tfidf[i])/2)):\n",
    "        unit_info = []\n",
    "        unit_info.append(test_data_tfidf[i][2*j])\n",
    "        unit_info.append(test_data_tfidf[i][2*j+1])\n",
    "        tfidf_info.append(unit_info)\n",
    "    test_tfidf.append(tfidf_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ongoing-hampshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37429193899782137"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(train_count, y_train)\n",
    "dummy_clf.score(dev_count,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "announced-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix\n",
    "def DtoM(data):\n",
    "    m = np.zeros((len(data),2038))\n",
    "    for i in range(0,len(data)):\n",
    "        for j in range(0,len(data[i])):\n",
    "            m[i][int(data[i][j][0])]=float(data[i][j][1])\n",
    "    return m\n",
    "count_m = DtoM(train_count)\n",
    "tfidf_m = DtoM(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intermediate-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set score is:  0.497103778168093\n",
      "The dev set score is:  0.45786492374727666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(count_m, y_train)\n",
    "print(\"The train set score is: \", clf.score(DtoM(train_count),y_train))\n",
    "print(\"The dev set score is: \", clf.score(DtoM(dev_count),y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trying-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set score is:  0.48306737919952164\n",
      "The dev set score is:  0.444880174291939\n"
     ]
    }
   ],
   "source": [
    "#clf_tfidf = LogisticRegression().fit(tfidf_m, y_train)\n",
    "#print(\"The train set score is: \", clf.score(tfidf_m,y_train))\n",
    "#print(\"The dev set score is: \", clf.score(DtoM(dev_tfidf),y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cathedral-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmax(m):\n",
    "    m_sum = sum(m)\n",
    "    pos = np.where(sum(count_m)==np.max(sum(count_m)))[0][0]\n",
    "    m = np.delete(m,pos, axis = 1)\n",
    "    return m\n",
    "count_m1 = cutmax(count_m)\n",
    "count_m_dev = DtoM(dev_count)\n",
    "count_m1_dev = cutmax(DtoM(dev_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expensive-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2037 features per sample; expecting 2038",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d4dc4b988a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf_cutmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The train set score is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The dev set score is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_m1_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \"\"\"\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2037 features per sample; expecting 2038"
     ]
    }
   ],
   "source": [
    "#clf_cutmax = LogisticRegression().fit(count_m1, y_train)\n",
    "#print(\"The train set score is: \", clf.score(count_m1,y_train))\n",
    "#print(\"The dev set score is: \", clf.score(count_m1_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,5):\n",
    "#    count_m1 = cutmax(count_m1)\n",
    "#    count_m1_dev = cutmax(count_m1_dev)\n",
    "#clf_cutmax5 = LogisticRegression().fit(count_m1, y_train)\n",
    "#print(\"The train set score is: \", clf.score(count_m1,y_train))\n",
    "#print(\"The dev set score is: \", clf.score(count_m1_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cutmin(m):\n",
    "#    m_sum = sum(m)\n",
    "#    pos = np.where(sum(count_m)==np.min(sum(count_m)))[0][0]\n",
    "#    m = np.delete(m,pos, axis = 1)\n",
    "#    return m\n",
    "#count_m2 = cutmin(count_m)\n",
    "#count_m2_dev = cutmin(DtoM(dev_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,10):\n",
    "#    count_m2 = cutmin(count_m2)\n",
    "#clf_cutmin10 = LogisticRegression().fit(count_m2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"The train set score is: \", clf_cutmin10.score(count_m2,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stone-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev_cut = cutmin(DtoM(dev_count))\n",
    "#for i in range(0,16):\n",
    "#    dev_cut = cutmin(dev_cut)\n",
    "#print(\"The dev set score is: \", clf_cutmin10.score(dev_cut,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "empirical-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "M_clf = MultinomialNB()\n",
    "B_clf = BernoulliNB()\n",
    "M_clf.fit(count_m,y_train)\n",
    "B_clf.fit(count_m,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "trained-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set score is:  0.49113195560372214\n",
      "The dev set score is:  0.4541176470588235\n"
     ]
    }
   ],
   "source": [
    "count_m_dev = DtoM(dev_count)\n",
    "print(\"The train set score is: \", M_clf.score(count_m,y_train))\n",
    "print(\"The dev set score is: \", M_clf.score(count_m_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "qualified-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set score is:  0.49285100340072496\n",
      "The dev set score is:  0.45647058823529413\n"
     ]
    }
   ],
   "source": [
    "print(\"The train set score is: \", B_clf.score(count_m,y_train))\n",
    "print(\"The dev set score is: \", B_clf.score(count_m_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "looking-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set score is:  0.49059381890205167\n",
      "The dev set score is:  0.46352941176470586\n"
     ]
    }
   ],
   "source": [
    "tfidf_m_dev = DtoM(dev_tfidf)\n",
    "M_clf.fit(tfidf_m,y_train)\n",
    "print(\"The train set score is: \", M_clf.score(tfidf_m,y_train))\n",
    "print(\"The dev set score is: \", M_clf.score(tfidf_m_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "brazilian-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "sigmoid = CalibratedClassifierCV(LogisticRegression(), cv=2, method='sigmoid')\n",
    "isotonic = CalibratedClassifierCV(MultinomialNB(), cv=2, method='isotonic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "breathing-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\ktyalex\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set score is:  0.493396614223252\n",
      "The dev set score is:  0.4645751633986928\n",
      "The train set score is:  0.49022758698008145\n",
      "The dev set score is:  0.46265795206971677\n"
     ]
    }
   ],
   "source": [
    "sigmoid.fit(tfidf_m,y_train)\n",
    "isotonic.fit(tfidf_m,y_train)\n",
    "print(\"The train set score is: \", sigmoid.score(tfidf_m,y_train))\n",
    "print(\"The dev set score is: \", sigmoid.score(tfidf_m_dev,y_dev))\n",
    "print(\"The train set score is: \", isotonic.score(tfidf_m,y_train))\n",
    "print(\"The dev set score is: \", isotonic.score(tfidf_m_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "public-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n",
    "                             f1_score)\n",
    "y_pred = sigmoid.predict(DtoM(test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "sporting-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"predict.csv\",\"w\")\n",
    "f1.write(\"id,region\\n\")\n",
    "for i in range(0, len(y_pred)):\n",
    "    f1.write(str(i+1)+\",\"+y_pred[i]+\"\\n\")\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-input",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
